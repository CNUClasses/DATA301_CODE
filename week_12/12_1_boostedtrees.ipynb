{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosted trees verses random forest\n",
    "\n",
    "\n",
    "Compare LightGBM, catbost, sklearn's GradientBoostingRegressor, with sklearn's Random Forest<br>\n",
    "LightGBM is a microsoft gradient boosted tree product<br>\n",
    "catboost is a Yandex gradient boosted tree product<br>\n",
    "\n",
    "See <a href=\"https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db\">CatBoost vs. Light GBM vs. XGBoost</a> for relative comparisons<br>\n",
    "See <a href=\"https://towardsdatascience.com/boosting-showdown-scikit-learn-vs-xgboost-vs-lightgbm-vs-catboost-in-sentiment-classification-f7c7f46fd956\">Scikit-Learn vs XGBoost vs LightGBM vs CatBoost in Sentiment Classification</a> for another relative comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install LightGBM\n",
    "conda and pip both have the same version (3.3.2) and the last upload was 3 months ago. This package is currently being maintained. Prefer conda so anaconda can coordinate LightGBMs dependencies with all other conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !conda install -c conda-forge lightgbm -y\n",
    "import lightgbm\n",
    "lightgbm.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install catboost\n",
    "conda and pip both have the same version (1.0.4) and the last upload was 2 months ago. This package is currently being maintained. Prefer conda so anaconda can coordinate catboosts dependencies with all other conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !conda install -c conda-forge catboost -y\n",
    "import catboost\n",
    "catboost.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Price($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Price($)  \n",
       "0    -122.23     4.526  \n",
       "1    -122.22     3.585  \n",
       "2    -122.24     3.521  \n",
       "3    -122.25     3.413  \n",
       "4    -122.25     3.422  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "calif_housing = fetch_california_housing()\n",
    "\n",
    "for line in calif_housing.DESCR.split(\"\\n\")[5:22]:\n",
    "    print(line)\n",
    "\n",
    "calif_housing_df = pd.DataFrame(data=calif_housing.data, columns=calif_housing.feature_names)\n",
    "calif_housing_df[\"Price($)\"] = calif_housing.target\n",
    "\n",
    "calif_housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = calif_housing.data, calif_housing.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R squared - a way to qualify a models predictions\n",
    "\n",
    "The following regressors use R squared as the default objective to optimize.  See <a href=\"https://www.youtube.com/watch?v=2AQKmw14mHM\">Statquest: R-squared, Clearly Explained!!!</a> for a great explanation plus examples.\n",
    "\n",
    "Usually 0<R squared<1  .  It ranges between these 2 values and is interpreted as how well the model fits the data. (In statistics this is called explained variance)\n",
    "\n",
    "If R squared =0,the line fitted to data is no more accurate than taking the mean of the data.<br>\n",
    "If R squared =1,the line fitted to the data is a perfect match<br>\n",
    "If R squared is negative then the line fitted to the data is a worse fit than just taking the average value of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It was not clear what objective lightGBM optimizes\n",
    "#so I implemented R squared below \n",
    "def rsquared(preds, y):\n",
    "    RSS=np.sum(np.square(preds-y))\n",
    "    ymean=np.sum(y)/len(y)\n",
    "    TSS=np.sum(np.square(y-ymean))\n",
    "    return 1-RSS/TSS\n",
    "\n",
    "def scoremodel(clf,X_test, y_test):\n",
    "    print(\"Score on test set: {:.2f}\".format(clf.score(X_test, y_test)))\n",
    "    #run score using rsquared function above\n",
    "    preds=clf.predict(X_test)\n",
    "    rsq=rsquared(preds,y_test)\n",
    "    print(\"Score on test set using rsquared: {:.2f}\".format(rsq))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest- default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.85 s, sys: 35.7 ms, total: 6.88 s\n",
      "Wall time: 6.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(random_state=42)\n",
    "_=clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.81\n",
      "Score on test set using rsquared: 0.81\n"
     ]
    }
   ],
   "source": [
    "scoremodel(clf,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm- default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.17 s, sys: 2.91 ms, total: 3.17 s\n",
      "Wall time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMRegressor\n",
    "clf = LGBMRegressor(random_state=42)\n",
    "_=clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.84\n",
      "Score on test set using rsquared: 0.84\n"
     ]
    }
   ],
   "source": [
    "scoremodel(clf,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost -default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 1.38 s, total: 16.6 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from catboost import CatBoostRegressor\n",
    "clf = CatBoostRegressor(silent=True, random_state=42)\n",
    "_=clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.86\n",
      "Score on test set using rsquared: 0.86\n"
     ]
    }
   ],
   "source": [
    "scoremodel(clf,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#took 10% of original dataset, dropped bunch of columns\n",
    "data = pd.read_csv(\"../datasets/kaggle/flights/flights_small.csv\")\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only later than 10 minutes is considered late\n",
    "data[\"ARRIVAL_DELAY\"] = (data[\"ARRIVAL_DELAY\"]>10)*1\n",
    "\n",
    "#convert to ordinal (even though they are categorical)\n",
    "cols = [\"AIRLINE\",\"FLIGHT_NUMBER\",\"DESTINATION_AIRPORT\",\"ORIGIN_AIRPORT\"]\n",
    "for item in cols:\n",
    "    data[item] = data[item].astype(\"category\").cat.codes +1\n",
    "\n",
    "#unlbalanced dataset, make sure you get a stratified sample\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop([\"ARRIVAL_DELAY\"], axis=1), data[\"ARRIVAL_DELAY\"], stratify=data[\"ARRIVAL_DELAY\"],\n",
    "                                                random_state=10, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    111559\n",
       "1     31276\n",
       "Name: ARRIVAL_DELAY, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.head()\n",
    "# X_test.shape\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def score_classifier_model(clf,X_test, y_test):\n",
    "    res = clf.predict(X_test)\n",
    "    print (classification_report(y_test, res))\n",
    "    print(confusion_matrix(y_test,res))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest- default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 155 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfc = RandomForestClassifier(random_state=42)\n",
    "_=clfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    111559\n",
      "           1       0.71      0.17      0.28     31276\n",
      "\n",
      "    accuracy                           0.80    142835\n",
      "   macro avg       0.76      0.58      0.58    142835\n",
      "weighted avg       0.79      0.80      0.75    142835\n",
      "\n",
      "[[109344   2215]\n",
      " [ 25809   5467]]\n"
     ]
    }
   ],
   "source": [
    "score_classifier_model(clfc,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro avg (precision)   =(.81+.71)/2\n",
    "# weighted avg (precision)= (111559/142835)*.81 + ((31276/142835)*.71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm- default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 307 ms, total: 24.2 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "clf_lgbm = LGBMClassifier(random_state=42)\n",
    "_=clf_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88    111559\n",
      "           1       0.74      0.12      0.20     31276\n",
      "\n",
      "    accuracy                           0.80    142835\n",
      "   macro avg       0.77      0.55      0.54    142835\n",
      "weighted avg       0.79      0.80      0.73    142835\n",
      "\n",
      "[[110268   1291]\n",
      " [ 27610   3666]]\n"
     ]
    }
   ],
   "source": [
    "score_classifier_model(clf_lgbm,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost -default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 20s, sys: 7.33 s, total: 4min 28s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from catboost import CatBoostClassifier\n",
    "clf_catboost = CatBoostClassifier(silent=True, random_state=42)\n",
    "_=clf_catboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    111559\n",
      "           1       0.72      0.19      0.31     31276\n",
      "\n",
      "    accuracy                           0.81    142835\n",
      "   macro avg       0.77      0.59      0.60    142835\n",
      "weighted avg       0.79      0.81      0.76    142835\n",
      "\n",
      "[[109215   2344]\n",
      " [ 25226   6050]]\n"
     ]
    }
   ],
   "source": [
    "score_classifier_model(clf_catboost,X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice that catboost consistantly outperforms Random Forest and LightGBM for these 2 tasks?  See the articles mentioned in first cell for further evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
