{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test 1 - Clustering with 1 hard question\n",
    "If you skip any pre processing please give a reason why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "# Set max rows and columns displayed in jupyter\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "\n",
    "#the following gives access to utils folder\n",
    "#where utils package stores shared code\n",
    "import os\n",
    "import sys\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(\n",
    "                  os.getcwd(),\n",
    "                  os.pardir)\n",
    ")\n",
    "\n",
    "#only add it once\n",
    "if (PROJECT_ROOT not in sys.path):\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed to find utils\n",
    "PROJECT_ROOT=PROJECT_ROOT+\"/..\"\n",
    "PROJECT_ROOT\n",
    "if (PROJECT_ROOT not in sys.path):\n",
    "    sys.path.append(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X1, Y1 = make_gaussian_quantiles(n_features=2, n_classes=3)\n",
    "# sns.scatterplot(x=X1[:,0], y=X1[:,1], hue=Y1)\n",
    "# plt.scatter(X1[:, 0], X1[:, 1], marker=\"o\", c=Y1, s=25, edgecolor=\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1 = make_classification( class_sep=2.0, n_repeated=3,  n_features=10, n_redundant=2, n_informative=5, n_clusters_per_class=1, n_classes=5, random_state=42)\n",
    "plt.figure(figsize=(20,10))\n",
    "ax=sns.scatterplot(x=X1[:,0], y=X1[:,1], hue=Y1)\n",
    "\n",
    "df=pd.DataFrame(data=X1, columns=('a','b','c','d','e','f','g','h','i','j'))\n",
    "\n",
    "# df.describe()\n",
    "\n",
    "#scale these hugely\n",
    "df['a']=df['a']*1000\n",
    "df['e']=df['e']*120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c anaconda sympy -y\n",
    "\n",
    "#which are redundant\n",
    "# from sympy import Matrix\n",
    "# np.linalg.matrix_rank(X1)\n",
    "# _, inds = Matrix(X1).rref(iszerofunc=lambda x: abs(x)<1e-3)\n",
    "# inds\n",
    "#d and G are redundant\n",
    "\n",
    "#create a catagorical\n",
    "# df['d']=pd.qcut(df['d'], 10,labels=['xxxxsmall','xxxsmall','xxsmall','xsmall','small', 'med','large','xlarge','xxlarge', 'xxxlarge'])\n",
    "df['d']=pd.cut(df['d'], 10,labels=['xxxxsmall','xxxsmall','xxsmall','xsmall','small', 'med','large','xlarge','xxlarge', 'xxxlarge'])\n",
    "\n",
    "# a=pd.cut(np.array([1, 7, 5, 4, 6, 3]), 3,labels=['bad','med','good'])\n",
    "# /a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)\n",
    "\n",
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Kmeans clustering - 90 points\n",
    "<mark>(40 pts) For the above dataset, apply appropriate pre processing, standardization and dimensionality reduction. Please be sure to remove all redundant features.<br>\n",
    "(40 pts) Cluster the data using Kmeans<br>\n",
    "(10 pts) 3D scatterplot the clusters using cluster membership to assign point color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert size\n",
    "dic = {\"xxxxsmall\":0, \"xxxsmall\":1, \"xxsmall\":2, \"xsmall\":3, \"small\":4, \"med\":5, \"large\":6, \"xlarge\":7, \"xxlarge\":8, \"xxxlarge\":9}\n",
    "# dic= {v:i for i,v in enumerate(df.d.unique().tolist())}  #this way changes the order\n",
    "df.d=df.d.map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.d.value_counts()\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=df.corr()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "#to find pairs\n",
    "to_drop=[(col,row) for col in upper.columns for row in upper[f'{col}'].index.tolist() if not pd.isnull(upper.loc[f'{row}',f'{col}']) and upper.loc[f'{row}',f'{col}']>0.95]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['g','j','b'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid submission\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# df1= pd.DataFrame(StandardScaler().fit_transform(df), columns=df.columns)\n",
    "# df1.describe()\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df=(df.pipe(ut.scale,df.columns.tolist(),StandardScaler()))\n",
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=.95, whiten=True)\n",
    "features_pca=pd.DataFrame(pca.fit_transform(df))\n",
    "print(f'Orig #features={df.shape[1]}, number features containing 95% of variance={features_pca.shape[1]}')\n",
    "\n",
    "# features_pca\n",
    "pca.explained_variance_ratio_\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS- find numb clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans(random_state=RANDOM_SEED)\n",
    "MIN_CLUSTERS=2\n",
    "MAX_CLUSTERS=12\n",
    "# plt.clf()\n",
    "plt.close()\n",
    "visualizer = KElbowVisualizer(model, k=(MIN_CLUSTERS,MAX_CLUSTERS))\n",
    "\n",
    "a=visualizer.fit(features_pca)        # Fit the data to the visualizer\n",
    "\n",
    "visualizer.show();        # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS assign cluster membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# initialize with k-means++, this puts the initial cluster choices as far away from each other\n",
    "# as possible which increases the chances for convergence\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=RANDOM_SEED).fit(features_pca.iloc[:,[0,1,2,3]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster']=kmeans.labels_\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors1 = {-1:\"brown\",\n",
    "            0:\"cyan\",\n",
    "           1:\"orange\", \n",
    "           2:\"purple\",\n",
    "           3:\"green\",\n",
    "          4:\"gray\",\n",
    "          5:\"red\",\n",
    "          6:\"blue\"}\n",
    "# %%capture\n",
    "# importing required libraries\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection, Line3DCollection\n",
    "%matplotlib ipympl\n",
    "plt.close()\n",
    "\n",
    "# creating figure\n",
    "fig = plt.figure(figsize=(20,10));\n",
    "\n",
    "ax = Axes3D(fig,auto_add_to_figure=False);\n",
    "ignore=ax.set_facecolor(\"white\");\n",
    "ignore=ax.grid(color=\"black\");\n",
    "\n",
    "ignore=fig.add_axes(ax,frameon=False)  #<Axes3D:>\n",
    "colors=df['cluster'].map(colors1)\n",
    "# creating the plot\n",
    "ignore=ax.scatter(df.iloc[:,0], df.iloc[:,1], df.iloc[:,2], c=colors)  #<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f98ea314070>\n",
    "\n",
    "# setting title and labels\n",
    "ignore=ax.set_title(\"3D plot\")\n",
    "plt.show();\n",
    "plt.figure().clear();\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To_Plot = [ col for col in df.columns]\n",
    "# plt.close()\n",
    "# plt.figure()\n",
    "# sns.pairplot(data=df[To_Plot])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10 pts) Hard question (note that part 2 is extra credit, do it last):\n",
    "for this dataset<br>\n",
    "1. (4 pts) write a function to find the euclidian distance between any 2 points <br>\n",
    "2. (4 pts-EXTRA CREDIT) given a point p1, write a function that will find the point p2 that is furthest from p1<br>\n",
    "3. (3 pts) what is the complexity (Big O) of the above procedure<br>\n",
    "4. (3 pts) what is the complexity (Big O) if you apply part 2 to every point in the dataset <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "import math\n",
    "def dst1(pt1,pt2):\n",
    "    return(math.dist(pt1,pt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 \n",
    "# get a point to find max dist to\n",
    "start_here=0\n",
    "pt1=df.iloc[start_here,:]\n",
    "\n",
    "# find the max dist\n",
    "dsts={}\n",
    "for i in range(len(df)):\n",
    "    dsts[i]=dst1(pt1,df.iloc[i,:])\n",
    "\n",
    "#get index and max distance\n",
    "key=max(dsts, key=dsts.get)\n",
    "print(f'The point furthest from {start_here} is pt[{key}] at a distance of {dsts[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 O(n) compare 1 to all once\n",
    "# Q4 O(n**2) compare all to all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
